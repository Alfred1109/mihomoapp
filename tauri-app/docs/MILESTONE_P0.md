# P0 æ¶æ„æ”¹è¿› Milestone

## ğŸ“‹ æ¦‚è§ˆ

**ç›®æ ‡**: è§£å†³æ¶æ„ä¸­çš„ 3 ä¸ª P0 ä¸¥é‡ç¼ºé™·
**é¢„è®¡æ—¶é—´**: 1-2 å‘¨
**ä¼˜å…ˆçº§**: ğŸ”´ æœ€é«˜

---

## ğŸ¯ æ”¹è¿›ç›®æ ‡

### 1. çŠ¶æ€ç®¡ç†æ··ä¹± â†’ ç»Ÿä¸€çŠ¶æ€ç®¡ç†
- âŒ å½“å‰ï¼šå‰ç«¯æ¯ 5 ç§’è½®è¯¢ï¼Œå¤šç»„ä»¶é‡å¤ç»´æŠ¤çŠ¶æ€
- âœ… ç›®æ ‡ï¼šä½¿ç”¨ Tauri Events å®æ—¶æ¨é€ + Zustand ç»Ÿä¸€ç®¡ç†

### 2. è¿›ç¨‹ç®¡ç†ä¸å¯é  â†’ è¿›ç¨‹ç›‘æ§å’Œè‡ªåŠ¨é‡å¯
- âŒ å½“å‰ï¼šå¯åŠ¨åä¸å†ç›‘æ§ï¼Œå´©æºƒæ— æ³•æ£€æµ‹
- âœ… ç›®æ ‡ï¼šå®ç° watchdog æŒç»­ç›‘æ§ + è‡ªåŠ¨é‡å¯æœºåˆ¶

### 3. é…ç½®æ–‡ä»¶å¹¶å‘é—®é¢˜ â†’ å®‰å…¨çš„é…ç½®ç®¡ç†
- âŒ å½“å‰ï¼šæ— æ–‡ä»¶é”ï¼Œå¯èƒ½æ•°æ®ç«äº‰å’ŒæŸå
- âœ… ç›®æ ‡ï¼šæ–‡ä»¶é”ä¿æŠ¤ + åŸå­å†™å…¥ + é…ç½®ç®¡ç†å™¨å•ä¾‹

---

## ğŸ“… å®æ–½è®¡åˆ’

### Phase 1: ç»Ÿä¸€çŠ¶æ€ç®¡ç† (3-4 å¤©)

#### Task 1.1: å®ç° Tauri Events çŠ¶æ€æ¨é€

**æ–‡ä»¶**: `backend/src/main.rs`, `backend/src/mihomo.rs`

**å®ç°å†…å®¹**:
```rust
// backend/src/events.rs (æ–°å»º)
use tauri::Manager;
use serde::{Serialize, Deserialize};

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct MihomoStatusEvent {
    pub running: bool,
    pub process_id: Option<u32>,
    pub timestamp: u64,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct ConfigChangeEvent {
    pub config_path: String,
    pub timestamp: u64,
}

pub fn emit_mihomo_status(app: &tauri::AppHandle, status: MihomoStatusEvent) {
    app.emit_all("mihomo-status", status).ok();
}

pub fn emit_config_change(app: &tauri::AppHandle, event: ConfigChangeEvent) {
    app.emit_all("config-change", event).ok();
}
```

**ä¿®æ”¹ç‚¹**:
1. åˆ›å»º `events.rs` æ¨¡å—
2. å®šä¹‰äº‹ä»¶ç±»å‹
3. åœ¨çŠ¶æ€å˜åŒ–æ—¶å‘é€äº‹ä»¶
4. ç§»é™¤å‰ç«¯è½®è¯¢é€»è¾‘

**éªŒæ”¶æ ‡å‡†**:
- âœ… å¯åŠ¨/åœæ­¢ mihomo æ—¶ç«‹å³æ¨é€äº‹ä»¶
- âœ… å‰ç«¯å®æ—¶æ”¶åˆ°çŠ¶æ€æ›´æ–°ï¼ˆ< 100msï¼‰
- âœ… ç§»é™¤æ‰€æœ‰ 5 ç§’è½®è¯¢ä»£ç 

---

#### Task 1.2: å‰ç«¯é›†æˆ Zustand çŠ¶æ€ç®¡ç†

**æ–‡ä»¶**: `src/store/appStore.ts` (æ–°å»º), `src/App.tsx`

**å®ç°å†…å®¹**:
```typescript
// src/store/appStore.ts
import { create } from 'zustand';
import { listen } from '@tauri-apps/api/event';

interface MihomoStatus {
  running: boolean;
  processId: number | null;
  timestamp: number;
}

interface AppStore {
  // çŠ¶æ€
  mihomoStatus: MihomoStatus;
  isAdmin: boolean;
  adminCheckDone: boolean;
  
  // æ“ä½œ
  setMihomoStatus: (status: MihomoStatus) => void;
  setIsAdmin: (isAdmin: boolean) => void;
  setAdminCheckDone: (done: boolean) => void;
  
  // åˆå§‹åŒ–ç›‘å¬
  initEventListeners: () => void;
}

export const useAppStore = create<AppStore>((set) => ({
  mihomoStatus: {
    running: false,
    processId: null,
    timestamp: 0,
  },
  isAdmin: false,
  adminCheckDone: false,
  
  setMihomoStatus: (status) => set({ mihomoStatus: status }),
  setIsAdmin: (isAdmin) => set({ isAdmin }),
  setAdminCheckDone: (done) => set({ adminCheckDone: done }),
  
  initEventListeners: () => {
    // ç›‘å¬ mihomo çŠ¶æ€å˜åŒ–
    listen('mihomo-status', (event: any) => {
      set({
        mihomoStatus: {
          running: event.payload.running,
          processId: event.payload.process_id,
          timestamp: event.payload.timestamp,
        },
      });
    });
    
    // ç›‘å¬é…ç½®å˜åŒ–
    listen('config-change', (event: any) => {
      console.log('Config changed:', event.payload);
    });
  },
}));
```

**ä¿®æ”¹ç‚¹**:
1. å®‰è£… `zustand`: `npm install zustand`
2. åˆ›å»ºå…¨å±€çŠ¶æ€ store
3. åœ¨ `App.tsx` ä¸­ä½¿ç”¨ store
4. ç§»é™¤ç»„ä»¶å†…éƒ¨çŠ¶æ€

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰ç»„ä»¶ä½¿ç”¨ç»Ÿä¸€çš„ store
- âœ… çŠ¶æ€å˜åŒ–è‡ªåŠ¨åŒæ­¥åˆ°æ‰€æœ‰ç»„ä»¶
- âœ… æ— é‡å¤è¯·æ±‚å’ŒçŠ¶æ€ä¸ä¸€è‡´

---

### Phase 2: è¿›ç¨‹ç›‘æ§å’Œè‡ªåŠ¨é‡å¯ (3-4 å¤©)

#### Task 2.1: å®ç°è¿›ç¨‹ç›‘æ§ Watchdog

**æ–‡ä»¶**: `backend/src/watchdog.rs` (æ–°å»º)

**å®ç°å†…å®¹**:
```rust
// backend/src/watchdog.rs
use std::sync::Arc;
use tokio::sync::RwLock;
use tokio::time::{interval, Duration};
use sysinfo::{System, SystemExt, ProcessExt, Pid};
use tauri::Manager;

pub struct ProcessWatchdog {
    process_id: Arc<RwLock<Option<u32>>>,
    auto_restart: Arc<RwLock<bool>>,
    app_handle: tauri::AppHandle,
}

impl ProcessWatchdog {
    pub fn new(app_handle: tauri::AppHandle) -> Self {
        Self {
            process_id: Arc::new(RwLock::new(None)),
            auto_restart: Arc::new(RwLock::new(true)),
            app_handle,
        }
    }
    
    pub async fn set_process(&self, pid: u32) {
        let mut process_id = self.process_id.write().await;
        *process_id = Some(pid);
    }
    
    pub async fn clear_process(&self) {
        let mut process_id = self.process_id.write().await;
        *process_id = None;
    }
    
    pub async fn set_auto_restart(&self, enabled: bool) {
        let mut auto_restart = self.auto_restart.write().await;
        *auto_restart = enabled;
    }
    
    pub async fn start_monitoring(&self) {
        let process_id = self.process_id.clone();
        let auto_restart = self.auto_restart.clone();
        let app_handle = self.app_handle.clone();
        
        tokio::spawn(async move {
            let mut interval = interval(Duration::from_secs(3));
            let mut system = System::new_all();
            
            loop {
                interval.tick().await;
                
                let pid = {
                    let pid_lock = process_id.read().await;
                    *pid_lock
                };
                
                if let Some(pid) = pid {
                    system.refresh_processes();
                    
                    // æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
                    let process_exists = system.process(Pid::from(pid as usize)).is_some();
                    
                    if !process_exists {
                        tracing::warn!("Mihomo process {} not found, may have crashed", pid);
                        
                        // æ¸…é™¤è¿›ç¨‹ ID
                        {
                            let mut pid_lock = process_id.write().await;
                            *pid_lock = None;
                        }
                        
                        // å‘é€è¿›ç¨‹åœæ­¢äº‹ä»¶
                        crate::events::emit_mihomo_status(
                            &app_handle,
                            crate::events::MihomoStatusEvent {
                                running: false,
                                process_id: None,
                                timestamp: std::time::SystemTime::now()
                                    .duration_since(std::time::UNIX_EPOCH)
                                    .unwrap()
                                    .as_secs(),
                            },
                        );
                        
                        // æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨é‡å¯
                        let should_restart = {
                            let restart_lock = auto_restart.read().await;
                            *restart_lock
                        };
                        
                        if should_restart {
                            tracing::info!("Auto-restarting mihomo...");
                            
                            // ç­‰å¾… 2 ç§’åé‡å¯
                            tokio::time::sleep(Duration::from_secs(2)).await;
                            
                            // è°ƒç”¨å¯åŠ¨å‡½æ•°
                            match crate::mihomo::start_mihomo().await {
                                Ok(new_pid) => {
                                    tracing::info!("Mihomo restarted with PID: {}", new_pid);
                                    let mut pid_lock = process_id.write().await;
                                    *pid_lock = Some(new_pid);
                                    
                                    // å‘é€é‡å¯æˆåŠŸäº‹ä»¶
                                    crate::events::emit_mihomo_status(
                                        &app_handle,
                                        crate::events::MihomoStatusEvent {
                                            running: true,
                                            process_id: Some(new_pid),
                                            timestamp: std::time::SystemTime::now()
                                                .duration_since(std::time::UNIX_EPOCH)
                                                .unwrap()
                                                .as_secs(),
                                        },
                                    );
                                }
                                Err(e) => {
                                    tracing::error!("Failed to restart mihomo: {}", e);
                                }
                            }
                        }
                    }
                }
            }
        });
    }
}
```

**ä¾èµ–æ·»åŠ **:
```toml
# Cargo.toml
[dependencies]
sysinfo = "0.30"
tracing = "0.1"
tracing-subscriber = "0.3"
```

**ä¿®æ”¹ç‚¹**:
1. åˆ›å»º `watchdog.rs` æ¨¡å—
2. åœ¨ `main.rs` ä¸­åˆå§‹åŒ– watchdog
3. å¯åŠ¨/åœæ­¢æ—¶æ›´æ–° watchdog çŠ¶æ€
4. æ·»åŠ æ—¥å¿—è®°å½•

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ¯ 3 ç§’æ£€æŸ¥ä¸€æ¬¡è¿›ç¨‹çŠ¶æ€
- âœ… è¿›ç¨‹å´©æºƒå 5 ç§’å†…æ£€æµ‹åˆ°
- âœ… è‡ªåŠ¨é‡å¯æˆåŠŸç‡ > 95%
- âœ… å‘é€çŠ¶æ€å˜åŒ–äº‹ä»¶

---

#### Task 2.2: æ·»åŠ è¿›ç¨‹è‡ªåŠ¨é‡å¯é…ç½®

**æ–‡ä»¶**: `src/components/Dashboard.tsx`

**å®ç°å†…å®¹**:
```typescript
// Dashboard.tsx æ·»åŠ è‡ªåŠ¨é‡å¯å¼€å…³
import { Switch, FormControlLabel } from '@mui/material';

const [autoRestart, setAutoRestart] = useState(true);

const handleAutoRestartChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
  const enabled = event.target.checked;
  setAutoRestart(enabled);
  
  try {
    await invoke('set_auto_restart', { enabled });
    showNotification(
      enabled ? 'å·²å¯ç”¨è‡ªåŠ¨é‡å¯' : 'å·²ç¦ç”¨è‡ªåŠ¨é‡å¯',
      'success'
    );
  } catch (error) {
    showNotification(`è®¾ç½®å¤±è´¥: ${error}`, 'error');
  }
};

// UI ç»„ä»¶
<FormControlLabel
  control={
    <Switch
      checked={autoRestart}
      onChange={handleAutoRestartChange}
      color="primary"
    />
  }
  label="è¿›ç¨‹å´©æºƒæ—¶è‡ªåŠ¨é‡å¯"
/>
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… ç”¨æˆ·å¯ä»¥å¼€å…³è‡ªåŠ¨é‡å¯
- âœ… è®¾ç½®æŒä¹…åŒ–ä¿å­˜
- âœ… å´©æºƒæ—¶æ ¹æ®è®¾ç½®å†³å®šæ˜¯å¦é‡å¯

---

### Phase 3: å®‰å…¨çš„é…ç½®ç®¡ç† (3-4 å¤©)

#### Task 3.1: å®ç°é…ç½®æ–‡ä»¶é”æœºåˆ¶

**æ–‡ä»¶**: `backend/src/config_manager.rs` (æ–°å»º)

**å®ç°å†…å®¹**:
```rust
// backend/src/config_manager.rs
use std::sync::Arc;
use tokio::sync::RwLock;
use std::path::PathBuf;
use anyhow::{Result, Context};
use fs2::FileExt;
use std::fs::File;

pub struct ConfigManager {
    config_path: PathBuf,
    lock: Arc<RwLock<()>>,
}

impl ConfigManager {
    pub fn new(config_path: PathBuf) -> Self {
        Self {
            config_path,
            lock: Arc::new(RwLock::new(())),
        }
    }
    
    /// è¯»å–é…ç½®ï¼ˆå¸¦é”ï¼‰
    pub async fn read_config(&self) -> Result<serde_json::Value> {
        let _guard = self.lock.read().await;
        
        let file = File::open(&self.config_path)
            .context("Failed to open config file")?;
        
        // è·å–å…±äº«é”
        file.lock_shared()
            .context("Failed to acquire shared lock")?;
        
        let content = std::fs::read_to_string(&self.config_path)
            .context("Failed to read config file")?;
        
        let yaml_value: serde_yaml::Value = serde_yaml::from_str(&content)
            .context("Failed to parse YAML")?;
        
        let json_value = serde_json::to_value(yaml_value)
            .context("Failed to convert to JSON")?;
        
        // é”ä¼šåœ¨ file drop æ—¶è‡ªåŠ¨é‡Šæ”¾
        file.unlock().ok();
        
        Ok(json_value)
    }
    
    /// å†™å…¥é…ç½®ï¼ˆå¸¦é” + åŸå­å†™å…¥ï¼‰
    pub async fn write_config(&self, config: serde_json::Value) -> Result<()> {
        let _guard = self.lock.write().await;
        
        // å…ˆåˆ›å»ºå¤‡ä»½
        self.create_backup().await?;
        
        // è½¬æ¢ä¸º YAML
        let yaml_value: serde_yaml::Value = serde_json::from_value(config)
            .context("Failed to convert from JSON")?;
        
        let yaml_content = serde_yaml::to_string(&yaml_value)
            .context("Failed to serialize YAML")?;
        
        // åŸå­å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½å
        let temp_path = self.config_path.with_extension("yaml.tmp");
        
        {
            let temp_file = File::create(&temp_path)
                .context("Failed to create temp file")?;
            
            // è·å–ç‹¬å é”
            temp_file.lock_exclusive()
                .context("Failed to acquire exclusive lock")?;
            
            std::fs::write(&temp_path, yaml_content)
                .context("Failed to write temp file")?;
            
            // åŒæ­¥åˆ°ç£ç›˜
            temp_file.sync_all()
                .context("Failed to sync temp file")?;
            
            temp_file.unlock().ok();
        }
        
        // åŸå­é‡å‘½å
        std::fs::rename(&temp_path, &self.config_path)
            .context("Failed to rename temp file")?;
        
        tracing::info!("Config saved successfully: {:?}", self.config_path);
        
        Ok(())
    }
    
    /// åˆ›å»ºå¤‡ä»½
    async fn create_backup(&self) -> Result<()> {
        if !self.config_path.exists() {
            return Ok(());
        }
        
        let backup_dir = self.config_path.parent()
            .context("Failed to get parent dir")?
            .join("backups");
        
        std::fs::create_dir_all(&backup_dir)
            .context("Failed to create backup dir")?;
        
        let timestamp = chrono::Local::now().format("%Y%m%d_%H%M%S");
        let backup_path = backup_dir.join(format!("config_{}.yaml", timestamp));
        
        std::fs::copy(&self.config_path, &backup_path)
            .context("Failed to create backup")?;
        
        tracing::info!("Backup created: {:?}", backup_path);
        
        Ok(())
    }
}

// å…¨å±€å•ä¾‹
lazy_static::lazy_static! {
    static ref CONFIG_MANAGER: Arc<RwLock<Option<ConfigManager>>> = Arc::new(RwLock::new(None));
}

pub async fn init_config_manager(config_path: PathBuf) {
    let mut manager = CONFIG_MANAGER.write().await;
    *manager = Some(ConfigManager::new(config_path));
}

pub async fn get_config_manager() -> Result<Arc<RwLock<Option<ConfigManager>>>> {
    Ok(CONFIG_MANAGER.clone())
}
```

**ä¾èµ–æ·»åŠ **:
```toml
# Cargo.toml
[dependencies]
fs2 = "0.4"  # æ–‡ä»¶é”
lazy_static = "1.4"
chrono = "0.4"
```

**ä¿®æ”¹ç‚¹**:
1. åˆ›å»º `config_manager.rs` æ¨¡å—
2. æ›¿æ¢ `config.rs` ä¸­çš„ç›´æ¥è¯»å†™
3. åœ¨ `main.rs` ä¸­åˆå§‹åŒ–ç®¡ç†å™¨
4. æ‰€æœ‰é…ç½®æ“ä½œé€šè¿‡ç®¡ç†å™¨

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰é…ç½®è¯»å†™éƒ½é€šè¿‡ç®¡ç†å™¨
- âœ… å¹¶å‘è¯»å†™ä¸ä¼šå¯¼è‡´æ•°æ®æŸå
- âœ… å†™å…¥å¤±è´¥æ—¶é…ç½®æ–‡ä»¶ä¸å—å½±å“
- âœ… è‡ªåŠ¨åˆ›å»ºå¤‡ä»½

---

#### Task 3.2: é‡æ„ç°æœ‰é…ç½®æ“ä½œ

**æ–‡ä»¶**: `backend/src/config.rs`, `backend/src/subscription.rs`

**ä¿®æ”¹å†…å®¹**:
```rust
// config.rs - ä½¿ç”¨é…ç½®ç®¡ç†å™¨
pub async fn load_config() -> Result<serde_json::Value> {
    let manager_lock = crate::config_manager::get_config_manager().await?;
    let manager_opt = manager_lock.read().await;
    let manager = manager_opt.as_ref()
        .context("Config manager not initialized")?;
    
    manager.read_config().await
}

pub async fn save_config(config: serde_json::Value) -> Result<()> {
    let manager_lock = crate::config_manager::get_config_manager().await?;
    let manager_opt = manager_lock.read().await;
    let manager = manager_opt.as_ref()
        .context("Config manager not initialized")?;
    
    manager.write_config(config).await
}
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰æ¨¡å—ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®ç®¡ç†å™¨
- âœ… ç§»é™¤æ‰€æœ‰ç›´æ¥æ–‡ä»¶æ“ä½œ
- âœ… æµ‹è¯•å¹¶å‘åœºæ™¯æ— é—®é¢˜

---

### Phase 4: ç»Ÿä¸€é”™è¯¯å¤„ç† (2-3 å¤©)

#### Task 4.1: å®šä¹‰é”™è¯¯æšä¸¾

**æ–‡ä»¶**: `backend/src/error.rs` (æ–°å»º)

**å®ç°å†…å®¹**:
```rust
// backend/src/error.rs
use thiserror::Error;

#[derive(Error, Debug)]
pub enum AppError {
    #[error("é…ç½®é”™è¯¯: {0}")]
    ConfigError(String),
    
    #[error("è¿›ç¨‹é”™è¯¯: {0}")]
    ProcessError(String),
    
    #[error("ç½‘ç»œé”™è¯¯: {0}")]
    NetworkError(String),
    
    #[error("æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {0}")]
    FileSystemError(String),
    
    #[error("æƒé™é”™è¯¯: {0}")]
    PermissionError(String),
    
    #[error("éªŒè¯é”™è¯¯: {0}")]
    ValidationError(String),
    
    #[error("è®¢é˜…é”™è¯¯: {0}")]
    SubscriptionError(String),
    
    #[error("IO é”™è¯¯: {0}")]
    IoError(#[from] std::io::Error),
    
    #[error("YAML é”™è¯¯: {0}")]
    YamlError(#[from] serde_yaml::Error),
    
    #[error("JSON é”™è¯¯: {0}")]
    JsonError(#[from] serde_json::Error),
    
    #[error("HTTP é”™è¯¯: {0}")]
    HttpError(#[from] reqwest::Error),
    
    #[error("å…¶ä»–é”™è¯¯: {0}")]
    Other(#[from] anyhow::Error),
}

pub type AppResult<T> = Result<T, AppError>;

impl From<AppError> for String {
    fn from(error: AppError) -> Self {
        error.to_string()
    }
}
```

**ä¾èµ–æ·»åŠ **:
```toml
# Cargo.toml
[dependencies]
thiserror = "1.0"
```

**ä¿®æ”¹ç‚¹**:
1. åˆ›å»º `error.rs` æ¨¡å—
2. æ›¿æ¢æ‰€æœ‰ `Result<T, String>` ä¸º `AppResult<T>`
3. ä½¿ç”¨ `?` æ“ä½œç¬¦ä¼ æ’­é”™è¯¯
4. æä¾›è¯¦ç»†çš„é”™è¯¯ä¸Šä¸‹æ–‡

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰é”™è¯¯éƒ½æœ‰æ˜ç¡®çš„ç±»å‹
- âœ… é”™è¯¯ä¿¡æ¯åŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡
- âœ… å‰ç«¯æ˜¾ç¤ºå‹å¥½çš„é”™è¯¯æç¤º

---

### Phase 5: æµ‹è¯•å’ŒéªŒè¯ (2-3 å¤©)

#### Task 5.1: ç¼–å†™å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `backend/src/config_manager.rs`, `backend/src/watchdog.rs`

**æµ‹è¯•å†…å®¹**:
```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;
    
    #[tokio::test]
    async fn test_concurrent_config_read() {
        let dir = tempdir().unwrap();
        let config_path = dir.path().join("config.yaml");
        
        // åˆ›å»ºæµ‹è¯•é…ç½®
        std::fs::write(&config_path, "port: 7890").unwrap();
        
        let manager = ConfigManager::new(config_path);
        
        // å¹¶å‘è¯»å–
        let handles: Vec<_> = (0..10)
            .map(|_| {
                let manager = manager.clone();
                tokio::spawn(async move {
                    manager.read_config().await.unwrap()
                })
            })
            .collect();
        
        for handle in handles {
            handle.await.unwrap();
        }
    }
    
    #[tokio::test]
    async fn test_atomic_write() {
        let dir = tempdir().unwrap();
        let config_path = dir.path().join("config.yaml");
        
        let manager = ConfigManager::new(config_path.clone());
        
        let config = serde_json::json!({
            "port": 7890,
            "socks-port": 7891,
        });
        
        manager.write_config(config.clone()).await.unwrap();
        
        let read_config = manager.read_config().await.unwrap();
        assert_eq!(config, read_config);
    }
}
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æœ‰å•å…ƒæµ‹è¯•
- âœ… æµ‹è¯•è¦†ç›–ç‡ > 60%
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡

---

#### Task 5.2: é›†æˆæµ‹è¯•

**æµ‹è¯•åœºæ™¯**:
1. âœ… å¯åŠ¨ mihomo â†’ æ£€æµ‹çŠ¶æ€ â†’ åœæ­¢ mihomo
2. âœ… å¯åŠ¨ mihomo â†’ æ‰‹åŠ¨ kill è¿›ç¨‹ â†’ è‡ªåŠ¨é‡å¯
3. âœ… å¹¶å‘ä¿®æ”¹é…ç½® â†’ éªŒè¯æ•°æ®å®Œæ•´æ€§
4. âœ… è®¢é˜…æ›´æ–°æ—¶ä¿å­˜é…ç½® â†’ æ— å†²çª
5. âœ… å‰ç«¯çŠ¶æ€å®æ—¶æ›´æ–° â†’ æ— å»¶è¿Ÿ

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰åœºæ™¯æµ‹è¯•é€šè¿‡
- âœ… æ— æ•°æ®æŸå
- âœ… æ— è¿›ç¨‹æ³„æ¼

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

| Phase | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | çŠ¶æ€ | è´Ÿè´£äºº |
|-------|------|---------|------|--------|
| 1 | Tauri Events çŠ¶æ€æ¨é€ | 2å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 1 | Zustand çŠ¶æ€ç®¡ç† | 1å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 2 | è¿›ç¨‹ç›‘æ§ Watchdog | 2å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 2 | è‡ªåŠ¨é‡å¯é…ç½® | 1å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 3 | é…ç½®æ–‡ä»¶é”æœºåˆ¶ | 2å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 3 | é‡æ„é…ç½®æ“ä½œ | 1å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 4 | ç»Ÿä¸€é”™è¯¯å¤„ç† | 2å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 5 | å•å…ƒæµ‹è¯• | 1å¤© | ğŸ”² å¾…å¼€å§‹ | - |
| 5 | é›†æˆæµ‹è¯• | 1å¤© | ğŸ”² å¾…å¼€å§‹ | - |

**æ€»è®¡**: 13 å¤©

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] å‰ç«¯çŠ¶æ€å®æ—¶æ›´æ–°ï¼ˆ< 100ms å»¶è¿Ÿï¼‰
- [ ] è¿›ç¨‹å´©æºƒå 5 ç§’å†…æ£€æµ‹å¹¶é‡å¯
- [ ] å¹¶å‘é…ç½®æ“ä½œæ— æ•°æ®æŸå
- [ ] æ‰€æœ‰é”™è¯¯éƒ½æœ‰å‹å¥½æç¤º

### æ€§èƒ½éªŒæ”¶
- [ ] CPU å ç”¨ < 5%ï¼ˆç©ºé—²æ—¶ï¼‰
- [ ] å†…å­˜å ç”¨ < 100MB
- [ ] çŠ¶æ€æ›´æ–°å»¶è¿Ÿ < 100ms

### è´¨é‡éªŒæ”¶
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 60%
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ— ç¼–è¯‘è­¦å‘Š
- [ ] ä»£ç é€šè¿‡ clippy æ£€æŸ¥

---

## ğŸ”§ å¼€å‘ç¯å¢ƒå‡†å¤‡

### ä¾èµ–å®‰è£…
```bash
# å‰ç«¯
cd tauri-app
npm install zustand

# åç«¯
cd backend
cargo add sysinfo fs2 lazy_static chrono thiserror tracing tracing-subscriber
```

### å¼€å‘å·¥å…·
```bash
# Rust æ ¼å¼åŒ–å’Œæ£€æŸ¥
cargo fmt
cargo clippy

# è¿è¡Œæµ‹è¯•
cargo test

# å‰ç«¯å¼€å‘
npm run tauri:dev
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### é£é™©ç‚¹
1. **çŠ¶æ€è¿ç§»é£é™©**: å‰ç«¯çŠ¶æ€ç®¡ç†æ”¹åŠ¨è¾ƒå¤§ï¼Œéœ€è¦å……åˆ†æµ‹è¯•
2. **è¿›ç¨‹ç›‘æ§æ€§èƒ½**: watchdog ä¸åº”å ç”¨è¿‡å¤šèµ„æº
3. **æ–‡ä»¶é”å…¼å®¹æ€§**: Windows å’Œ Linux çš„æ–‡ä»¶é”è¡Œä¸ºå¯èƒ½ä¸åŒ
4. **å‘åå…¼å®¹**: ç¡®ä¿æ—§é…ç½®æ–‡ä»¶ä»ç„¶å¯ç”¨

### å›æ»šæ–¹æ¡ˆ
1. ä¿ç•™æ—§ä»£ç çš„ git åˆ†æ”¯
2. æ¯ä¸ª Phase å®Œæˆååˆ›å»º tag
3. å‡ºç°é—®é¢˜å¯å¿«é€Ÿå›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬

### æ²Ÿé€šè®¡åˆ’
- æ¯æ—¥ç«™ä¼šï¼šåŒæ­¥è¿›åº¦å’Œé—®é¢˜
- Phase å®Œæˆåï¼šä»£ç  Review
- æœ€ç»ˆéªŒæ”¶ï¼šå®Œæ•´åŠŸèƒ½æ¼”ç¤º

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Tauri Events æ–‡æ¡£](https://tauri.app/v1/guides/features/events)
- [Zustand æ–‡æ¡£](https://github.com/pmndrs/zustand)
- [fs2 æ–‡ä»¶é”æ–‡æ¡£](https://docs.rs/fs2/)
- [thiserror æ–‡æ¡£](https://docs.rs/thiserror/)
- [sysinfo è¿›ç¨‹ç›‘æ§](https://docs.rs/sysinfo/)

---

**åˆ›å»ºæ—¶é—´**: 2026-01-24
**æœ€åæ›´æ–°**: 2026-01-24
**ç‰ˆæœ¬**: v1.0
